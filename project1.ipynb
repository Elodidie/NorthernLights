{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 30 features, 250'000 samples, column 22 is categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data set into training/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import *\n",
    "y_tr, x_tr, y_te, x_te = split_data(tX, y, 0.8, seed=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "undefined_features = [[4, 5, 6, 12, 22, 23, 24, 25, 26,\n",
    "                       27, 28, 29], [4, 5, 6, 12, 22, 26, 27, 28], [22], [22]]\n",
    "PRI_jet_num = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get jet sets for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jet tot size: 200000  y tot size:  200000\n"
     ]
    }
   ],
   "source": [
    "jet_train, y_jet_train, index = get_jets(x_tr, y_tr, PRI_jet_num, undefined_features, list_ = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get jet sets for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jet tot size: 50000  y tot size:  50000\n"
     ]
    }
   ],
   "source": [
    "jet_test, y_jet_test, index_te = get_jets(x_te, y_te, PRI_jet_num, undefined_features, list_ = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://opendata.cern.ch/record/328, https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing other -999 (non defined) entries, replacing them and standardizing data**\n",
    "\n",
    "Deal with nan !!\n",
    "https://towardsdatascience.com/working-with-missing-data-in-machine-learning-9c0a430df4ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr = standard(x_tr)\n",
    "x_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79792\n",
      "62185\n",
      "40362\n",
      "17661\n",
      "20121\n",
      "15359\n",
      "10017\n",
      "4503\n",
      "200000 50000 250000\n"
     ]
    }
   ],
   "source": [
    "check1 = 0\n",
    "check2 = 0\n",
    "\n",
    "for jet in jet_train:\n",
    "    jet_ = standard(jet)\n",
    "    jet = jet_\n",
    "    check1 += len(jet_)\n",
    "for jet in jet_test:\n",
    "    jet_ = standard(jet)\n",
    "    jet = jet_\n",
    "    check2 += len(jet_)\n",
    "\n",
    "print(check1, check2, check1 + check2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(jet_test[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different splitting are possible\n",
    "- simple splitting\n",
    "- **k-folds** for each method. k = 10 ?\n",
    "- train / test / validation set ? -> Do we keep a test set\n",
    "- train with entire set ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![How to proceed](train_test_valid_split_process_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The process can be summarised as follows:\n",
    "\n",
    "1) Separate out from the data a final holdout testing set (perhaps something like ~10% if we have a good amount of data).\n",
    "\n",
    "2) Shuffle the remaining data randomly.\n",
    "\n",
    "3) Split this data into k equally sized sets/folds.\n",
    "\n",
    "4) For each unique fold:\n",
    "- 4.1 Use this fold as the validation fold\n",
    "- 4.2 Combine the other k-1 folds as the training data\n",
    "- 4.3 Fit the model with the training data\n",
    "- 4.4 Evaluate the model with the validation fold\n",
    "- 4.5 Keep the evaluation scores, discard the model and begin again at 4.1 with a new validation fold\n",
    "\n",
    "5) Evaluate your model against the whole set of k validation scores, and if you are unhappy make adjustments and repeat from 1.\n",
    "\n",
    "When you are finally happy, combine all k folds into one complete training data set, train again, and perform a final test on the holdout testing set.\n",
    "\n",
    "https://algotrading101.com/learn/train-test-split-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do I have to split first my data into test / training set and perform cross validation on training test...?\n",
    "- Do I have to optimize for gamma ? NO\n",
    "- Which k to choose for k folds cross validation?\n",
    "-- Common value is k = 10. For statistical reasons (https://machinelearningmastery.com/k-fold-cross-validation/#:~:text=When%20a%20specific%20value%20for,learning%20model%20on%20unseen%20data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Basic least_squares Gradient descent:\n",
    "- don't forget to optimize\n",
    "- for gamma: The most commonly used rates are : 0.001, 0.003, 0.01, 0.03, 0.1, 0.3. for degree 1 (https://towardsdatascience.com/gradient-descent-algorithm-and-its-variants-10f652806a3)\n",
    "- across k-folds -> 10-folds (for both cases)\n",
    "- for degrees (to test) across different gammas. Does it make any sense...?\n",
    "- across seeds...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For entire standardized set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all jets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform least_squares GD for degree 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7734318646156526\n",
      "0.8940274323040908\n",
      "0.8776259621297081\n",
      "0.8703956788129524\n"
     ]
    }
   ],
   "source": [
    "from implementations import least_squares_GD\n",
    "from utils import build_poly\n",
    "\n",
    "y_pred_list = []\n",
    "w_list = []\n",
    "rmse_list = []\n",
    "degree = 1\n",
    "\n",
    "for (jet, y_jet) in zip(jet_train, y_jet_train):\n",
    "    \n",
    "    x_augm = build_poly(jet,1)\n",
    "    initial_w = np.zeros((x_augm.shape[1],))\n",
    "    rmse, w = least_squares_GD(y_jet, x_augm, initial_w, 5000, 0.000001)\n",
    "    print(rmse)\n",
    "    w_list.append(w)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "for (jet_te, w) in zip(jet_test, w_list):\n",
    "    x_augm = build_poly(jet_te, degree)\n",
    "    y_pred = x_augm.dot(w)\n",
    "    \n",
    "    y_pred_list.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute accuracy on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74302"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from proj1_helpers import combine_jets\n",
    "from utils import accuracy_2\n",
    "\n",
    "y_predict = combine_jets(y_pred_list, index_te)\n",
    "accuracy_2(y_te, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final accuracy = 0.74302\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load jets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import get_jets_final\n",
    "jet_final, ind_list = get_jets_final(tX_test, 22, undefined_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jet = []\n",
    "\n",
    "for (jet, w) in zip(jet_final, w_list):\n",
    "    x_augm = build_poly(jet, 1)\n",
    "    y_pred = x_augm.dot(w)\n",
    "    final_jet.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute final y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = combine_jets(final_jet, ind_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568238 568238\n",
      "568238.0 568238\n"
     ]
    }
   ],
   "source": [
    "print(len(y_final), tX_test.shape[0])\n",
    "Y = predict_labels_2(y_final)\n",
    "final_check = np.abs(Y)\n",
    "print(np.sum(final_check), len(y_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import predict_labels_2\n",
    "Y = predict_labels_2(y_final)\n",
    "OUTPUT_PATH = 'GD_deg1.csv'\n",
    "create_csv_submission(ids_test, Y, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VErdict: accuracy = 0.743, F1 score = \t0.566\n",
    "SO test set is quite accurate :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Ridge regression\n",
    "\n",
    "- optimize over lambda for degree 1\n",
    "- select best_degree over all lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1) Grid search: Optimize for degree** across lambda (few) range, seed = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best degree =1, loss for k-folds cross validation=0.7391695016746421, best lambda=1.0\n"
     ]
    }
   ],
   "source": [
    "from cross_validation_phi import select_best_degree_ridge\n",
    "from implementations import ridge_regression\n",
    "\n",
    "best_degs = []\n",
    "best_lbds = []\n",
    "rmse_tot_te = []\n",
    "w_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for (jet, y_jet) in zip(jet_train, y_jet_train):\n",
    "    best_degree, rmse_te, best_lambda = select_best_degree_ridge(y_jet, jet, seed = 200, k_fold = 10)\n",
    "    best_degs.append(best_degree)\n",
    "    best_lbds.append(best_lambda)\n",
    "    rmse_tot_te.append(rmse_te)\n",
    "    \n",
    "    x_augm = build_poly(jet, best_degree)\n",
    "    rmse_tr, w = ridge_regression(y_jet, x_augm, best_lambda)\n",
    "    w_list.append(w)\n",
    "    \n",
    "for(jet, w, deg) in zip(jet_test, w_list, best_degs):\n",
    "    x_augm_te = build_poly(jet, deg)\n",
    "    y_pred = x_augm_te.dot(w)\n",
    "    y_pred_list.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7903\n"
     ]
    }
   ],
   "source": [
    "y_predict = combine_jets(y_pred_list, index_te)\n",
    "print(accuracy_2(y_te, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.7903"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data for final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split test set into jets and get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import get_jets_final\n",
    "jet_final, ind_list = get_jets_final(tX_test, 22, undefined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "final_jet = []\n",
    "\n",
    "for (jet, w, deg) in zip(jet_final, w_list, best_degs):\n",
    "    x_augm = build_poly(jet, deg )\n",
    "    y_pred = x_augm.dot(w)\n",
    "    final_jet.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568238 568238\n",
      "568238.0 568238\n"
     ]
    }
   ],
   "source": [
    "y_final = combine_jets(final_jet, ind_list)\n",
    "print(len(y_final), tX_test.shape[0])\n",
    "Y = predict_labels_2(y_final)\n",
    "final_check = np.abs(Y)\n",
    "print(np.sum(final_check), len(y_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'Ridge.csv'\n",
    "create_csv_submission(ids_test, Y, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.790, Fscore = 0.662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
